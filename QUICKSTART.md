# Guide de dÃ©marrage rapide OpenRAG

Ce guide vous permet de dÃ©marrer rapidement avec OpenRAG.

## Installation en 3 Ã©tapes

### 1. PrÃ©requis
- Docker & Docker Compose installÃ©s
- 4GB RAM minimum (8GB recommandÃ©)
- 20GB d'espace disque

### 2. Installation

```bash
# Cloner le projet
git clone https://github.com/your-org/openrag.git
cd openrag

# Lancer l'installation automatique
make install

# Ou manuellement :
cp .env.example .env
docker-compose up -d
```

### 3. Premier test

```bash
# Attendre que les services dÃ©marrent (30 secondes)
docker-compose ps

# CrÃ©er un document de test
echo "OpenRAG est un systÃ¨me RAG open-source." > test.txt

# Uploader le document
curl -X POST http://localhost:8000/documents/upload -F "file=@test.txt"

# Attendre 10 secondes que le document soit traitÃ©

# Poser une question
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Qu'\''est-ce qu'\''OpenRAG ?"}'
```

## AccÃ¨s aux interfaces

- **API Swagger** : http://localhost:8000/docs
- **MinIO Console** : http://localhost:9001 (admin/admin123456)
- **Qdrant Dashboard** : http://localhost:6333/dashboard

## Commandes utiles

```bash
make start      # DÃ©marrer les services
make stop       # ArrÃªter les services
make logs       # Voir les logs
make test       # Lancer les tests
make status     # Voir le statut
```

## Configuration du LLM

Par dÃ©faut, OpenRAG utilise Ollama en local. Pour changer :

### Option 1 : Ollama (dÃ©faut)
```bash
# TÃ©lÃ©charger un modÃ¨le
docker exec -it openrag-ollama ollama pull llama3.1:8b
```

### Option 2 : OpenAI
```env
# Dans .env
LLM_PROVIDER=openai
LLM_MODEL=gpt-4-turbo
OPENAI_API_KEY=sk-...
```

### Option 3 : Anthropic Claude
```env
# Dans .env
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-sonnet-20240229
ANTHROPIC_API_KEY=sk-ant-...
```

## Structure du projet

```
openrag/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/              # API Gateway
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ orchestrator/ # Orchestrateur principal
â”‚   â”‚   â””â”€â”€ embedding/    # Service d'embeddings
â”‚   â””â”€â”€ database/         # Scripts SQL
â”œâ”€â”€ docs/                 # Documentation Mintlify
â”œâ”€â”€ scripts/              # Scripts utilitaires
â”œâ”€â”€ docker-compose.yml    # Configuration Docker
â””â”€â”€ .env                  # Configuration
```

## Troubleshooting

### Les services ne dÃ©marrent pas
```bash
docker-compose logs -f
```

### Pas de rÃ©sultats pour les requÃªtes
Attendez que les documents soient traitÃ©s :
```bash
curl http://localhost:8000/documents | jq '.documents[] | select(.status == "processed")'
```

### Ollama ne trouve pas le modÃ¨le
```bash
docker exec -it openrag-ollama ollama pull llama3.1:8b
```

## Documentation complÃ¨te

Pour plus de dÃ©tails, consultez la documentation complÃ¨te :

```bash
cd docs
npx mintlify dev
```

Puis visitez http://localhost:3000

## Support

- ğŸ“š Docs : https://docs.openrag.io
- ğŸ’¬ Discord : https://discord.gg/openrag
- ğŸ› Issues : https://github.com/your-org/openrag/issues
