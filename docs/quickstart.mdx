---
title: 'Démarrage rapide'
description: 'Lancez OpenRAG en moins de 10 minutes'
---

# Démarrage rapide

Ce guide vous permettra d'avoir un système RAG fonctionnel en moins de 10 minutes.

## Prérequis

Assurez-vous d'avoir installé :

<CardGroup cols={2}>
  <Card title="Docker" icon="docker">
    Version 20.10 ou supérieure
  </Card>
  <Card title="Docker Compose" icon="layer-group">
    Version 2.0 ou supérieure
  </Card>
  <Card title="Git" icon="git">
    Pour cloner le repository
  </Card>
  <Card title="4GB RAM minimum" icon="memory">
    8GB recommandés pour de meilleures performances
  </Card>
</CardGroup>

## Installation

### Étape 1 : Cloner le repository

```bash
git clone https://github.com/your-org/openrag.git
cd openrag
```

### Étape 2 : Configuration

Copiez le fichier d'environnement exemple et adaptez-le à vos besoins :

```bash
cp .env.example .env
```

Éditez `.env` pour configurer vos paramètres :

```bash .env
# Configuration LLM
LLM_PROVIDER=ollama  # ou openai, anthropic
LLM_MODEL=llama3.1:8b

# Si vous utilisez OpenAI
# OPENAI_API_KEY=sk-...

# Configuration Embedding
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

### Étape 3 : Lancer les services

```bash
docker-compose up -d
```

Cette commande va :
- Télécharger toutes les images Docker nécessaires
- Créer les volumes de données
- Démarrer tous les services

<Info>
  Le premier démarrage peut prendre 5-10 minutes selon votre connexion internet.
</Info>

### Étape 4 : Vérifier le statut

Vérifiez que tous les services sont démarrés :

```bash
docker-compose ps
```

Vous devriez voir tous les services avec le statut `Up` :

```
NAME                    STATUS
openrag-api            Up
openrag-orchestrator   Up
openrag-embedding      Up
openrag-postgres       Up
openrag-redis          Up
openrag-minio          Up
openrag-qdrant         Up
openrag-ollama         Up
```

### Étape 5 : Télécharger le modèle LLM (Ollama)

Si vous utilisez Ollama, téléchargez le modèle :

```bash
docker exec -it openrag-ollama ollama pull llama3.1:8b
```

<Tip>
  Alternatives légères : `llama3.1:3b`, `gemma:2b`, `phi3:mini`
</Tip>

## Premier test

### 1. Vérifier l'API

```bash
curl http://localhost:8000/health
```

Réponse attendue :
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "services": {
    "orchestrator": "healthy"
  }
}
```

### 2. Uploader un document de test

Créez un fichier de test :

```bash
echo "OpenRAG est un système RAG open-source qui permet d'interroger vos documents avec des LLM. Il supporte plusieurs formats de documents et s'intègre avec différents fournisseurs de LLM." > test_document.txt
```

Uploadez-le :

```bash
curl -X POST http://localhost:8000/documents/upload \
  -F "file=@test_document.txt" \
  -F "collection_id=default"
```

Réponse :
```json
{
  "document_id": "123e4567-e89b-12d3-a456-426614174000",
  "filename": "test_document.txt",
  "status": "processing",
  "message": "Document uploaded successfully and is being processed"
}
```

<Info>
  Le traitement du document (chunking + embedding + indexation) prend quelques secondes.
  Attendez 10-15 secondes avant de faire une requête.
</Info>

### 3. Poser une question

```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Qu'\''est-ce qu'\''OpenRAG ?",
    "max_results": 3,
    "use_llm": true
  }'
```

Réponse :
```json
{
  "query_id": "456e7890-e89b-12d3-a456-426614174111",
  "answer": "OpenRAG est un système RAG (Retrieval-Augmented Generation) open-source qui permet d'interroger vos documents en utilisant des modèles de langage (LLM). Il supporte plusieurs formats de documents et peut s'intégrer avec différents fournisseurs de LLM.",
  "sources": [
    {
      "document_id": "123e4567-e89b-12d3-a456-426614174000",
      "filename": "test_document.txt",
      "chunk_index": 0,
      "relevance_score": 0.92
    }
  ],
  "execution_time_ms": 1234,
  "timestamp": "2024-02-17T10:30:00Z"
}
```

## Accès aux interfaces

Une fois démarré, vous pouvez accéder à :

<CardGroup cols={2}>
  <Card title="API Documentation" icon="book" href="http://localhost:8000/docs">
    Swagger UI interactif - `http://localhost:8000/docs`
  </Card>
  <Card title="MinIO Console" icon="database" href="http://localhost:9001">
    Interface de gestion des fichiers - `http://localhost:9001`
  </Card>
  <Card title="Qdrant Dashboard" icon="vector-square" href="http://localhost:6333/dashboard">
    Dashboard Qdrant - `http://localhost:6333/dashboard`
  </Card>
  <Card title="Grafana (monitoring)" icon="chart-line" href="http://localhost:3000">
    Monitoring (optionnel) - `http://localhost:3000`
  </Card>
</CardGroup>

### Credentials par défaut

- **MinIO** : admin / admin123456
- **Grafana** : admin / admin

<Warning>
  Changez ces mots de passe avant de déployer en production !
</Warning>

## Télécharger plus de documents

Vous pouvez uploader des documents de différents formats :

### PDF
```bash
curl -X POST http://localhost:8000/documents/upload \
  -F "file=@rapport.pdf" \
  -F "collection_id=rapports"
```

### DOCX
```bash
curl -X POST http://localhost:8000/documents/upload \
  -F "file=@document.docx" \
  -F "collection_id=documents"
```

### Markdown
```bash
curl -X POST http://localhost:8000/documents/upload \
  -F "file=@README.md" \
  -F "collection_id=documentation"
```

## Vérifier les documents

Listez tous les documents uploadés :

```bash
curl http://localhost:8000/documents
```

Obtenir les détails d'un document :

```bash
curl http://localhost:8000/documents/{document_id}
```

## Arrêter les services

Pour arrêter tous les services :

```bash
docker-compose down
```

Pour arrêter ET supprimer les données :

```bash
docker-compose down -v
```

<Warning>
  L'option `-v` supprime tous les volumes, y compris vos documents et données !
</Warning>

## Prochaines étapes

<CardGroup cols={2}>
  <Card
    title="Guide d'upload de documents"
    icon="file-upload"
    href="/guides/upload-documents"
  >
    Apprenez à gérer efficacement vos documents
  </Card>
  <Card
    title="Configurer le LLM"
    icon="robot"
    href="/guides/llm-configuration"
  >
    Utilisez OpenAI, Anthropic ou d'autres LLM
  </Card>
  <Card
    title="Collections"
    icon="folder"
    href="/guides/collections"
  >
    Organisez vos documents par collections
  </Card>
  <Card
    title="API Reference"
    icon="code"
    href="/api-reference"
  >
    Documentation complète de l'API
  </Card>
</CardGroup>

## Troubleshooting

### Les services ne démarrent pas

Vérifiez les logs :
```bash
docker-compose logs -f
```

### Ollama ne répond pas

Vérifiez que le modèle est bien téléchargé :
```bash
docker exec -it openrag-ollama ollama list
```

### Pas de résultats pour les requêtes

Attendez que les documents soient complètement traités :
```bash
curl http://localhost:8000/documents | jq '.documents[] | select(.status == "processed")'
```

<Info>
  Pour plus d'aide, consultez notre [guide de troubleshooting](/guides/troubleshooting) ou rejoignez notre [Discord](https://discord.gg/openrag).
</Info>
