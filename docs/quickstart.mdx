---
title: 'Démarrage rapide'
description: 'Lancez OpenRAG en 5 minutes'
---

# Démarrage rapide

Installez et lancez OpenRAG avec toutes ses interfaces web en **5 minutes chrono**.

## Prérequis

<CardGroup cols={2}>
  <Card title="Docker 26.0+" icon="docker">
    Installation : [Guide](/installation/requirements#logiciels-requis)
  </Card>
  <Card title="Docker Compose 2.26+" icon="layer-group">
    Inclus avec Docker moderne
  </Card>
  <Card title="16 GB RAM minimum" icon="memory">
    32 GB recommandés avec GPU
  </Card>
  <Card title="50 GB stockage" icon="hard-drive">
    Pour Docker images + modèle LLM (4.9 GB)
  </Card>
</CardGroup>

<Warning>
**Important:** Le système nécessite **16 GB RAM minimum** pour faire fonctionner le LLM llama3.1:8b. Voir [Prérequis détaillés](/installation/requirements) pour plus d'informations.
</Warning>

## Installation en 4 étapes

### 1. Cloner le repository

```bash
git clone https://github.com/3ntrop1a/openrag.git
cd openrag
```

### 2. Lancer tous les services

```bash
# Démarrer les 10 microservices
sudo docker-compose up -d
```

<Info>
**Premier démarrage:** Téléchargement des images Docker et du modèle LLM (4.9 GB). Comptez **10-15 minutes** selon votre connexion.
</Info>

### 3. Vérifier que tout est démarré

```bash
# Voir l'état des 10 services
sudo docker-compose ps
```

Vous devriez voir **10 services** avec le statut `Up` :

```
NAME                       STATUS
openrag-api                Up
openrag-orchestrator       Up
openrag-embedding          Up  
openrag-frontend-user      Up  # NOUVEAU: Chat utilisateur
openrag-frontend-admin     Up  # NOUVEAU: Panel admin
openrag-postgres           Up
openrag-redis              Up
openrag-minio              Up
openrag-qdrant             Up
openrag-ollama             Up
```

### 4. Télécharger le modèle LLM

Si vous utilisez Ollama (configuration par défaut) :

```bash
docker exec -it openrag-ollama ollama pull llama3.1:8b
```

<Tip>
Alternatives légères : `llama3.1:3b` (2GB), `gemma:2b` (1.5GB), `phi3:mini` (2.3GB)
</Tip>

<Info>
Le téléchargement du modèle llama3.1:8b prend **4.9 GB**. Comptez 5-10 minutes selon votre connexion.
</Info>

## Accès aux interfaces web

Ouvrez votre navigateur et testez les interfaces :

<CardGroup cols={2}>
  <Card 
    title="Chat Utilisateur" 
    icon="messages"
    href="http://localhost:8501"
  >
    **Interface principale** - http://localhost:8501
    
    Chat interactif avec historique et sources
  </Card>
  <Card 
    title="Panel Admin" 
    icon="gauge"
    href="http://localhost:8502"
  >
    **Dashboard administration** - http://localhost:8502
    
    Gestion documents, upload, statistiques
  </Card>
  <Card 
    title="API Swagger" 
    icon="code"
    href="http://localhost:8000/docs"
  >
    **Documentation API** - http://localhost:8000/docs
    
    Tester l'API REST interactivement
  </Card>
  <Card 
    title="Qdrant Dashboard" 
    icon="database"
    href="http://localhost:6333/dashboard"
  >
    **Base vectorielle** - http://localhost:6333/dashboard
    
    Explorer les vecteurs indexés
  </Card>
</CardGroup>

## Premier test

### Option 1: Via l'interface Chat (Recommandé)

<Steps>
  <Step title="Ouvrir l'interface utilisateur">
    Naviguez vers http://localhost:8501
  </Step>
  
  <Step title="Poser une question de test">
    Dans le chat, tapez:
    ```
    Qu'est-ce qu'OpenRAG et comment ça fonctionne ?
    ```
    
    Cliquez "Envoyer" ou appuyez sur Entrée.
  </Step>
  
  <Step title="Observer la réponse">
    Le système va:
    1. Chercher dans les documents (100-200 ms)
    2. Générer une réponse avec le LLM (5-15 s après premier chargement)
    3. Afficher les sources en bas avec scores de pertinence
    
    **Important:** La première requête prend **50-75 secondes** (chargement du modèle LLM). Les suivantes sont beaucoup plus rapides (5-15s).
  </Step>
</Steps>

### Option 2: Via l'API REST (curl)

<Steps>
  <Step title="Vérifier la santé de l'API">
    ```bash
    curl http://localhost:8000/health | jq
    ```
    
    Réponse attendue:
    ```json
    {
      "status": "healthy",
      "timestamp": "2026-02-18T...",
      "version": "1.1.0",
      "services": {
        "database": "healthy",
        "redis": "healthy",
        "vector_store": "healthy",
        "orchestrator": "healthy"
      }
    }
    ```
  </Step>
  
  <Step title="Faire une recherche simple (sans LLM)">
    ```bash
    curl -X POST http://localhost:8000/query \
      -H "Content-Type: application/json" \
      -d '{
        "query": "configuration téléphone",
        "collection_id": "default",
        "max_results": 3,
        "use_llm": false
      }' | jq
    ```
    
    Retourne les documents similaires avec scores de pertinence.
  </Step>
  
  <Step title="Faire une requête avec LLM">
    ```bash
    curl -X POST http://localhost:8000/query \
      -H "Content-Type: application/json" \
      -d '{
        "query": "Comment configurer un poste Cisco ?",
        "collection_id": "default",
        "max_results": 5,
        "use_llm": true
      }' | jq -r '.answer'
    ```
    
    <Warning>
    **Première requête:** 50-75 secondes (chargement llama3.1:8b en RAM)  
    **Suivantes:** 5-15 secondes
    </Warning>
  </Step>
</Steps>

## Uploader vos propres documents

### Via l'interface admin (Recommandé)

<Steps>
  <Step title="Ouvrir le panel admin">
    http://localhost:8502
  </Step>
  
  <Step title="Aller dans Upload">
    Cliquez sur "Upload" dans la sidebar
  </Step>
  
  <Step title="Sélectionner un fichier PDF">
    - Cliquez "Browse files"
    - Choisissez un PDF
    - Remplissez les métadonnées (optionnel)
    - Cliquez "Upload"
  </Step>
  
  <Step title="Vérifier le processing">
    - Allez dans la section "Documents"
    - Vérifiez le statut (processing → processed)
    - Comptez 10-30 secondes par document selon la taille
  </Step>
</Steps>

### Via l'API

```bash
curl -X POST http://localhost:8000/documents/upload \
  -F "file=@mon_document.pdf" \
  -F "collection_id=default" \
  -F "metadata={\"category\":\"guide\",\"source\":\"documentation\"}"
```

## Accès MinIO (Stockage de fichiers)

**URL:** http://localhost:9001  
**Identifiants:** admin / admin123456

<Warning>
**Important:** Changez ce mot de passe avant tout déploiement en production !
</Warning>

## Commandes utiles

### Voir les logs en temps réel

```bash
# Tous les services
sudo docker-compose logs -f

# Un service spécifique
sudo docker-compose logs -f orchestrator
sudo docker-compose logs -f ollama
```

### Redémarrer un service

```bash
sudo docker-compose restart orchestrator
```

### Arrêter tout

```bash
sudo docker-compose down
```

### Nettoyer complètement (données incluses)

```bash
sudo docker-compose down -v  # Supprime aussi les volumes
```

<Warning>
L'option `-v` supprime tous les volumes, y compris vos documents et données indexées !
</Warning>

## Prochaines étapes

<CardGroup cols={2}>
  <Card
    title="Architecture système"
    icon="diagram-project"
    href="/architecture"
  >
    Comprendre le fonctionnement interne d'OpenRAG
  </Card>
  <Card
    title="Prérequis détaillés"
    icon="list-check"
    href="/installation/requirements"
  >
    Configuration GPU, optimisations, production
  </Card>
  <Card
    title="Tests & Validation"
    icon="flask-vial"
    href="/tests/overview"
  >
    Tests de charge, performance, qualité
  </Card>
  <Card
    title="API Reference"
    icon="code"
    href="/api-reference/introduction"
  >
    Documentation complète de l'API REST
  </Card>
</CardGroup>

## Dépannage rapide

### Les services ne démarrent pas

```bash
# Vérifiez les logs
sudo docker-compose logs -f

# Vérifiez l'espace disque (minimum 50 GB)
df -h

# Vérifiez la RAM (minimum 16 GB)
free -h
```

### Ollama ne répond pas

```bash
# Vérifiez que le modèle est téléchargé
docker exec -it openrag-ollama ollama list

# Si absent, téléchargez-le
docker exec -it openrag-ollama ollama pull llama3.1:8b
```

### Requêtes très lentes (>75s)

<Tip>
**Solution:** Utilisez un GPU ! Voir [Configuration GPU](/installation/requirements#gpu-nvidia-recommandé) pour passer de 50-75s à 1-3s par requête.
</Tip>

### Pas de résultats pour les requêtes

```bash
# Vérifiez que les documents sont traités
curl http://localhost:8000/documents | jq '.documents[] | {filename, status}'

# Statut "processed" = prêt
# Statut "processing" = en cours (attendez 10-30s)
```
