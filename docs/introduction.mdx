---
title: Introduction √† OpenRAG
description: 'Syst√®me RAG (Retrieval-Augmented Generation) complet et pr√™t pour la production'
---

# Bienvenue dans OpenRAG üöÄ

OpenRAG est une solution RAG (Retrieval-Augmented Generation) compl√®te, modulaire et pr√™te pour la production. Elle permet d'interroger vos documents en utilisant des mod√®les de langage avanc√©s avec un contexte pr√©cis et pertinent.

## Qu'est-ce qu'un syst√®me RAG ?

Un syst√®me RAG combine la **recherche d'information** avec la **g√©n√©ration de texte** pour fournir des r√©ponses pr√©cises bas√©es sur vos propres documents :

1. **Retrieval (Recherche)** : Trouve les passages pertinents dans votre base documentaire
2. **Augmented (Augmentation)** : Enrichit la requ√™te avec le contexte trouv√©
3. **Generation (G√©n√©ration)** : G√©n√®re une r√©ponse coh√©rente avec un LLM

### Workflow RAG

```mermaid
graph LR
    Q[Question] --> R[Recherche vectorielle]
    R --> D[Documents pertinents]
    D --> A[Augmentation contexte]
    A --> G[G√©n√©ration LLM]
    G --> Answer[R√©ponse avec sources]
```

## Fonctionnalit√©s principales

<CardGroup cols={2}>
  <Card
    title="Upload de documents"
    icon="file-upload"
  >
    PDF, DOCX, TXT, Markdown - Processing automatique
  </Card>
  <Card
    title="Recherche s√©mantique"
    icon="magnifying-glass"
  >
    Recherche vectorielle avanc√©e avec Qdrant
  </Card>
  <Card
    title="G√©n√©ration de r√©ponses"
    icon="robot"
  >
    Ollama, OpenAI, Anthropic Claude
  </Card>
  <Card
    title="Architecture modulaire"
    icon="cubes"
    href="/architecture"
  >
    Microservices d√©coupl√©s avec Docker
  </Card>
</CardGroup>

## Composants principaux

OpenRAG est compos√© de **10 services Docker** :

| Service | Port | R√¥le |
|---------|------|------|
| **frontend-user** | 8501 | Interface chat utilisateur (Streamlit) |
| **frontend-admin** | 8502 | Panel admin, upload, stats (Streamlit) |
| **api** | 8000 | API REST (FastAPI) |
| **orchestrator** | 8001 | Coordination workflows RAG |
| **embedding** | 8002 | G√©n√©ration embeddings (sentence-transformers) |
| **ollama** | 11434 | Serveur LLM local |
| **qdrant** | 6333 | Base vectorielle |
| **postgres** | 5432 | M√©tadonn√©es et historique |
| **redis** | 6379 | Cache et queues |
| **minio** | 9000/9001 | Stockage fichiers (S3-compatible) |

## Cas d'usage

<AccordionGroup>
  <Accordion icon="building" title="Base de connaissances d'entreprise">
    Cr√©ez un assistant IA qui conna√Æt tous vos documents internes, proc√©dures et politiques d'entreprise.
  </Accordion>
  
  <Accordion icon="scale-balanced" title="Assistance juridique">
    Interrogez rapidement des contrats, jurisprudences et documents l√©gaux avec citations pr√©cises.
  </Accordion>
  
  <Accordion icon="graduation-cap" title="Support client">
    R√©pondez automatiquement aux questions bas√©es sur votre documentation produit et FAQ.
  </Accordion>
  
  <Accordion icon="book" title="Recherche acad√©mique">
    Explorez et synth√©tisez de grandes collections de papiers de recherche scientifique.
  </Accordion>
</AccordionGroup>

## D√©marrage rapide

<Steps>
  <Step title="Cloner et lancer">
    ```bash
    git clone https://github.com/3ntrop1a/openrag.git
    cd openrag
    sudo docker-compose up -d
    ```
  </Step>
  
  <Step title="T√©l√©charger le mod√®le LLM">
    ```bash
    docker exec -it openrag-ollama ollama pull llama3.1:8b
    ```
  </Step>
  
  <Step title="Ouvrir l'interface chat">
    Naviguez vers http://localhost:8501 et posez votre premi√®re question !
  </Step>
</Steps>

<Info>
**Premi√®re fois ?** Le d√©marrage initial prend 10-15 minutes (t√©l√©chargement images Docker + mod√®le LLM 4.9 GB)
</Info>

## Prochaines √©tapes

<CardGroup cols={2}>
  <Card
    title="Guide de d√©marrage rapide"
    icon="rocket"
    href="/quickstart"
  >
    Installation compl√®te en 5 minutes
  </Card>
  <Card
    title="Architecture d√©taill√©e"
    icon="sitemap"
    href="/architecture"
  >
    Comprendre le fonctionnement interne
  </Card>
  <Card
    title="Pr√©requis syst√®me"
    icon="server"
    href="/installation/requirements"
  >
    Configuration minimale: 16 GB RAM, GPU optionnel
  </Card>
  <Card
    title="API Reference"
    icon="code"
    href="/api-reference/introduction"
  >
    Documentation compl√®te de l'API REST
  </Card>
</CardGroup>

## Caract√©ristiques techniques

<AccordionGroup>
  <Accordion icon="gauge-high" title="Performance">
    - **Avec GPU:** 1-3s par requ√™te
    - **Sans GPU:** 5-15s par requ√™te (apr√®s warm-up)
    - **Recherche vectorielle:** 100-200ms
    - **Indexation:** 10-30s par document PDF
  </Accordion>

  <Accordion icon="database" title="Scalabilit√©">
    - Architecture microservices horizontalement scalable
    - Support de millions de documents
    - Redis pour cache distribu√©
    - PostgreSQL pour m√©tadonn√©es
    - Qdrant pour recherche vectorielle haute performance
  </Accordion>

  <Accordion icon="shield-halved" title="S√©curit√©">
    - Donn√©es stock√©es localement (pas de cloud tiers)
    - Isolation des services Docker
    - Support des LLM locaux (Ollama) pour confidentialit√© totale
    - Compatible avec LLM cloud (OpenAI, Claude) si souhait√©
  </Accordion>

  <Accordion icon="puzzle-piece" title="Extensibilit√©">
    - Int√©gration facile de nouveaux formats de documents
    - Support multi-LLM (Ollama, OpenAI, Anthropic)
    - API REST pour int√©gration dans vos applications
    - Collection multiples pour segmentation des documents
  </Accordion>
</AccordionGroup>

## Support et contributions

- üêõ **Issues:** [GitHub Issues](https://github.com/3ntrop1a/openrag/issues)
- üíª **Code source:** [github.com/3ntrop1a/openrag](https://github.com/3ntrop1a/openrag)
- üìñ **Documentation:** Cette documentation Mintlify
