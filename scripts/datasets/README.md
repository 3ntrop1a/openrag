# Dataset Download Scripts

Scripts pour t√©l√©charger et importer des datasets scientifiques dans OpenRAG.

## üéØ Objectif

Tester OpenRAG avec des corpus cons√©quents (500-1000+ documents) pour valider les performances du syst√®me RAG, par opposition au corpus WTE limit√© (33 documents).

## üìö Datasets Disponibles

### 1. Wikipedia FR - Sciences (Recommand√©)
- **Source**: Wikipedia fran√ßais, cat√©gorie "Sciences"
- **Taille**: 1000 articles (configurable)
- **Langue**: Fran√ßais
- **Format**: JSON
- **Temps**: ~30 minutes de t√©l√©chargement

### 2. arXiv - Computer Science
- **Source**: arXiv.org
- **Taille**: 1000 papers (configurable)
- **Langue**: Anglais
- **Format**: JSON (abstracts)
- **Temps**: ~20 minutes de t√©l√©chargement

## üöÄ Utilisation Rapide

### Option 1: Wikipedia FR Sciences (1000 articles)

```bash
# 1. T√©l√©charger les articles
cd /home/adminrag/openrag
python scripts/datasets/download_wikipedia.py --limit 1000 --output /tmp/wikipedia_fr_1000.json

# 2. V√©rifier le fichier
du -h /tmp/wikipedia_fr_1000.json
cat /tmp/wikipedia_fr_1000.json | head -50

# 3. S'assurer qu'OpenRAG tourne
docker-compose ps
# Tous les services doivent √™tre "Up"

# 4. Importer dans OpenRAG
python scripts/datasets/import_to_openrag.py /tmp/wikipedia_fr_1000.json

# 5. Surveiller le processing
docker-compose logs -f orchestrator
# Attendre "‚úÖ Success!" pour tous les documents

# 6. Tester
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Qui a d√©couvert la relativit√© g√©n√©rale?", "use_llm": true}'
```

### Option 2: arXiv CS.AI (1000 papers)

```bash
# 1. Installer d√©pendance
pip install arxiv

# 2. T√©l√©charger les papers
python scripts/datasets/download_arxiv.py --category cs.AI --limit 1000 --output /tmp/arxiv_1000.json

# 3. Importer
python scripts/datasets/import_to_openrag.py /tmp/arxiv_1000.json

# 4. Tester
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What are transformer models?", "use_llm": true}'
```

## üìñ Scripts D√©taill√©s

### download_wikipedia.py

T√©l√©charge des articles Wikipedia fran√ßais de la cat√©gorie "Sciences".

**Arguments**:
- `--limit`: Nombre d'articles √† t√©l√©charger (default: 1000)
- `--output`: Fichier de sortie JSON (default: /tmp/wikipedia_fr_sciences_1000.json)

**Exemple**:
```bash
python scripts/datasets/download_wikipedia.py --limit 500 --output /tmp/wiki_500.json
```

**Output**:
```json
[
  {
    "title": "Relativit√© g√©n√©rale",
    "content": "La relativit√© g√©n√©rale est une th√©orie...",
    "url": "https://fr.wikipedia.org/wiki/Relativit√©_g√©n√©rale",
    "source": "wikipedia_fr",
    "category": "Sciences",
    "page_id": "12345"
  },
  ...
]
```

### download_arxiv.py

T√©l√©charge des papers arXiv d'une cat√©gorie sp√©cifique.

**Arguments**:
- `--category`: Cat√©gorie arXiv (cs.AI, cs.CL, cs.LG, cs.CV, etc.)
- `--limit`: Nombre de papers (default: 1000)
- `--output`: Fichier de sortie JSON

**Cat√©gories populaires**:
- `cs.AI`: Artificial Intelligence
- `cs.CL`: Computation and Language (NLP)
- `cs.CV`: Computer Vision
- `cs.LG`: Machine Learning
- `cs.IR`: Information Retrieval

**Exemple**:
```bash
python scripts/datasets/download_arxiv.py --category cs.CL --limit 500 --output /tmp/arxiv_nlp_500.json
```

**Output**:
```json
[
  {
    "title": "Attention Is All You Need",
    "content": "The dominant sequence transduction models...",
    "authors": ["Ashish Vaswani", "Noam Shazeer", ...],
    "url": "http://arxiv.org/abs/1706.03762",
    "published": "2017-06-12T17:58:16+00:00",
    "categories": ["cs.CL", "cs.LG"],
    "source": "arxiv"
  },
  ...
]
```

### import_to_openrag.py

Importe un dataset JSON dans OpenRAG via l'API.

**Arguments**:
- `dataset_file`: Chemin vers le fichier JSON (required)
- `--api`: URL de l'API OpenRAG (default: http://localhost:8000)

**Exemple**:
```bash
python scripts/datasets/import_to_openrag.py /tmp/wikipedia_fr_1000.json --api http://localhost:8000
```

**Ce qui se passe**:
1. Lit le fichier JSON
2. Pour chaque document:
   - Cr√©e un fichier texte avec m√©tadonn√©es
   - Upload via API `/upload`
   - Rate limiting (0.05s entre requ√™tes)
3. Affiche statistiques de succ√®s/erreurs

**Format upload√©**:
```
Title: Relativit√© g√©n√©rale

Source: https://fr.wikipedia.org/wiki/Relativit√©_g√©n√©rale
Category: Sciences

Content:
La relativit√© g√©n√©rale est une th√©orie de la gravitation...
```

## ‚è±Ô∏è Temps de Processing Estim√©s

| Dataset | T√©l√©chargement | Upload | Processing | Total |
|---------|----------------|--------|------------|-------|
| Wikipedia 500 | ~15 min | ~5 min | ~30 min | ~50 min |
| Wikipedia 1000 | ~30 min | ~10 min | ~1h | ~1h40 |
| arXiv 500 | ~10 min | ~5 min | ~15 min | ~30 min |
| arXiv 1000 | ~20 min | ~10 min | ~30 min | ~1h |

**Processing** = Extraction texte + Chunking + Embedding 768D + Stockage Qdrant

## üîç V√©rifications

### V√©rifier nombre de documents import√©s
```bash
curl -s http://localhost:8000/documents | python3 -c "import sys, json; d=json.load(sys.stdin); print(f'Documents: {len(d)}')"
```

### V√©rifier nombre de vecteurs dans Qdrant
```bash
curl -s http://localhost:6333/collections/documents_embeddings | python3 -m json.tool | grep points_count
```

### V√©rifier statut processing
```bash
curl -s http://localhost:8000/documents | python3 -c "import sys, json; d=json.load(sys.stdin); statuses = {}; [statuses.update({doc['status']: statuses.get(doc['status'], 0) + 1}) for doc in d]; print(statuses)"
```

Expected: `{'processed': 1000}` quand tout est fini

## üß™ Tests Sugg√©r√©s

### Wikipedia FR (apr√®s import)

```bash
# Test 1: Question factuelle
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Qui a d√©couvert la p√©nicilline?", "use_llm": true}'

# Test 2: Question th√©orique
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Explique le principe de la photosynth√®se", "use_llm": true}'

# Test 3: Comparaison
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Diff√©rence entre ADN et ARN", "use_llm": true}'
```

### arXiv CS.AI (apr√®s import)

```bash
# Test 1: Architecture
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What are transformer models?", "use_llm": true}'

# Test 2: Technique
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "How does self-attention work?", "use_llm": true}'

# Test 3: Application
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Applications of reinforcement learning", "use_llm": true}'
```

## üìä Comparaison R√©sultats

Comparer avec les r√©sultats WTE document√©s dans [`docs/experiments/wte-corpus-analysis.mdx`](../docs/experiments/wte-corpus-analysis.mdx).

**M√©triques √† observer**:
- Nombre de documents retourn√©s pertinents
- Position des documents les plus pertinents
- Scores de similarit√©
- Qualit√© de la r√©ponse LLM
- Temps de r√©ponse

## üêõ Troubleshooting

### Erreur: "Cannot connect to API"
```bash
# V√©rifier que les services tournent
docker-compose ps

# Red√©marrer si n√©cessaire
docker-compose restart api orchestrator
```

### Erreur: "arxiv module not found"
```bash
pip install arxiv
```

### Processing trop lent
```bash
# Augmenter les workers (dans .env)
EMBEDDING_BATCH_SIZE=64  # Default: 32

# Red√©marrer
docker-compose restart embedding-service
```

### Out of memory
```bash
# R√©duire batch size
EMBEDDING_BATCH_SIZE=16  # Default: 32

# Ou traiter par lots plus petits
python scripts/datasets/download_wikipedia.py --limit 100
python scripts/datasets/import_to_openrag.py /tmp/wikipedia_fr_100.json
# R√©p√©ter plusieurs fois
```

## üìù Logs

### Voir logs de processing
```bash
docker-compose logs -f orchestrator
```

### Voir logs d'embedding
```bash
docker-compose logs -f embedding-service
```

### Voir logs Qdrant
```bash
docker-compose logs -f qdrant
```

## üéì Pour la Soutenance

1. ‚úÖ Documenter corpus WTE (33 docs) = **√©chec pr√©visible**
2. ‚úÖ T√©l√©charger Wikipedia FR Sciences (1000 docs)
3. ‚úÖ Importer et processer
4. ‚úÖ Tester requ√™tes vari√©es
5. ‚úÖ Comparer r√©sultats WTE vs Wikipedia
6. ‚úÖ Montrer que volume de donn√©es critique pour RAG
7. ‚úÖ Documenter dans [`docs/experiments/`](../docs/experiments/)

## üìö Ressources

- [Wikipedia API Documentation](https://www.mediawiki.org/wiki/API:Main_page)
- [arXiv API Documentation](https://arxiv.org/help/api/)
- [OpenRAG Documentation](http://localhost:3000)

## üîÑ Prochaines √âtapes

Voir [`docs/experiments/DATASET_RECOMMENDATIONS.md`](../docs/experiments/DATASET_RECOMMENDATIONS.md) pour plus de datasets et recommandations.
